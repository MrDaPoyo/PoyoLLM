{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "cell_id": "a3d906151a3a4542a4c66a8d120991e1",
                "deepnote_cell_type": "markdown"
            },
            "source": [
                "# The PoyoModel3000\n",
                "This jupyter notebook will contain the model itself."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {
                "cell_id": "e412021656df4e7480fba04c246bd3da",
                "deepnote_cell_type": "code",
                "execution_context_id": "5c07c2dd-95b5-4d75-8e71-757b6df90be6",
                "execution_millis": 1237,
                "execution_start": 1745505459667,
                "source_hash": "c861570b"
            },
            "outputs": [],
            "source": [
                "import sys\n",
                "sys.path.append('.')\n",
                "from minbpe import BasicTokenizer\n",
                "\n",
                "tokenizer = BasicTokenizer()\n",
                "tokenizer.load(model_file=\"./output/tokenizer/poyo_tokenizer.model\")\n",
                "def get_vocab_size(tokenizer: BasicTokenizer) -> int:\n",
                "    vocab = tokenizer.vocab\n",
                "    special_tokens = tokenizer.special_tokens\n",
                "\n",
                "    return len(vocab) + len(special_tokens)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {
                "cell_id": "c0ca098cf393494e85dadddaa2e70019",
                "deepnote_cell_type": "code",
                "execution_context_id": "5c07c2dd-95b5-4d75-8e71-757b6df90be6",
                "execution_millis": 5910,
                "execution_start": 1745505460967,
                "source_hash": "490f889b"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CUDA available: False\n",
                        "Using device: cpu\n"
                    ]
                }
            ],
            "source": [
                "import torch\n",
                "torch.manual_seed(6969)\n",
                "\n",
                "block_size = 1024\n",
                "n_embd = 384\n",
                "n_head = 12\n",
                "n_layer = 12\n",
                "dropout = 0.2\n",
                "vocab_size = get_vocab_size(tokenizer)\n",
                "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
                "device = torch.cuda.is_available() and torch.cuda.current_device() if torch.cuda.is_available() else \"cpu\"\n",
                "print(f\"Using device: {device}\")\n",
                "a = torch.tensor([0], dtype=torch.float32, device=device)  # Fixed the syntax error in tensor creation"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cell_id": "94ce748d498b4272abffba6ca025d952",
                "deepnote_cell_type": "markdown"
            },
            "source": [
                "# The Head (drama here)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {
                "cell_id": "88ad53a635554fc29f38f5f371fd08bf",
                "deepnote_cell_type": "code",
                "execution_context_id": "5c07c2dd-95b5-4d75-8e71-757b6df90be6",
                "execution_millis": 0,
                "execution_start": 1745505466935,
                "source_hash": "eb098e53"
            },
            "outputs": [],
            "source": [
                "from typing import Optional, Tuple\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "from torch.nn import functional as F\n",
                "\n",
                "\n",
                "class Head(nn.Module):\n",
                "    \"\"\" one head of self-attention btw I do not have an attention span \"\"\"\n",
                "\n",
                "    def __init__(self, head_size: int) -> None:\n",
                "        super().__init__()\n",
                "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
                "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
                "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
                "        self.register_buffer('tril', torch.tril(\n",
                "            torch.ones(block_size, block_size)))\n",
                "\n",
                "        self.dropout = nn.Dropout(dropout)\n",
                "\n",
                "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
                "        # input of size (batch, time-step, channels)\n",
                "        # output of size (batch, time-step, head size)\n",
                "        _, T, _ = x.shape\n",
                "        k = self.key(x)   # (B,T,hs)\n",
                "        q = self.query(x)  # (B,T,hs)\n",
                "        # compute attention scores (\"affinities\")\n",
                "        # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n",
                "        weights = q @ k.transpose(-2, -1) * k.shape[-1]**-0.5\n",
                "        weights = weights.masked_fill(\n",
                "            self.tril[:T, :T] == 0, float('-inf'))  # (B, T, T)\n",
                "        weights = F.softmax(weights, dim=-1)  # (B, T, T)\n",
                "        weights = self.dropout(weights)\n",
                "        # perform the weighted aggregation of the values\n",
                "        v = self.value(x)  # (B,T,hs)\n",
                "        out = weights @ v  # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
                "        return out"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cell_id": "96a90593ffcf47098340aa59fd8f8244",
                "deepnote_cell_type": "markdown"
            },
            "source": [
                "# Multi-Head Attention"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {
                "cell_id": "4e4c9caa494840fc949c6c8e9f989474",
                "deepnote_cell_type": "code",
                "execution_context_id": "5c07c2dd-95b5-4d75-8e71-757b6df90be6",
                "execution_millis": 1,
                "execution_start": 1745505467004,
                "source_hash": "7e703f76"
            },
            "outputs": [],
            "source": [
                "class MultiHeadAttention(nn.Module):\n",
                "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
                "\n",
                "    def __init__(self, num_heads: int, head_size: int) -> None:\n",
                "        super().__init__()\n",
                "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
                "        self.projection = nn.Linear(head_size * num_heads, n_embd)\n",
                "        self.dropout = nn.Dropout(dropout)\n",
                "\n",
                "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
                "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
                "        out = self.dropout(self.projection(out))\n",
                "        return out"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cell_id": "6e967f140032491e85d320df2abe650d",
                "deepnote_cell_type": "markdown"
            },
            "source": [
                "# The BLOCK "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {
                "cell_id": "8e735145a2004069b6ca6417420b7012",
                "deepnote_cell_type": "code",
                "execution_context_id": "5c07c2dd-95b5-4d75-8e71-757b6df90be6",
                "execution_millis": 1,
                "execution_start": 1745505467078,
                "source_hash": "f37d4556"
            },
            "outputs": [],
            "source": [
                "class FeedFoward(nn.Module):\n",
                "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
                "\n",
                "    def __init__(self, n_embd: int) -> None:\n",
                "        super().__init__()\n",
                "        self.net = nn.Sequential(\n",
                "            nn.Linear(n_embd, 4 * n_embd),\n",
                "            nn.ReLU(),\n",
                "            nn.Linear(4 * n_embd, n_embd),\n",
                "            nn.Dropout(dropout),\n",
                "        )\n",
                "\n",
                "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
                "        return self.net(x)\n",
                "\n",
                "\n",
                "class Block(nn.Module):\n",
                "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
                "\n",
                "    def __init__(self, n_embd: int, n_head: int) -> None:\n",
                "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
                "        super().__init__()\n",
                "        head_size = n_embd // n_head\n",
                "        self.self_attention = MultiHeadAttention(n_head, head_size)\n",
                "        self.feed_forward = FeedFoward(n_embd)\n",
                "        self.layer_norm_1 = nn.LayerNorm(n_embd)\n",
                "        self.layer_norm_2 = nn.LayerNorm(n_embd)\n",
                "\n",
                "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
                "        x = x + self.self_attention(self.layer_norm_1(x))\n",
                "        x = x + self.feed_forward(self.layer_norm_2(x))\n",
                "        return x"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cell_id": "58fc0627b02649aba44751ad5bdfc046",
                "deepnote_cell_type": "markdown"
            },
            "source": [
                "# Assembling the model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {
                "cell_id": "56cb2e400a7542ca8b45339a5676fcb2",
                "deepnote_cell_type": "code",
                "execution_context_id": "5c07c2dd-95b5-4d75-8e71-757b6df90be6",
                "execution_millis": 1,
                "execution_start": 1745505467144,
                "source_hash": "73b62f32"
            },
            "outputs": [],
            "source": [
                "class GPTLanguageModel(nn.Module):\n",
                "\n",
                "    def __init__(self) -> None:\n",
                "        super().__init__()\n",
                "        # each token directly reads off the logits for the next token from a lookup table\n",
                "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
                "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
                "        self.blocks = nn.Sequential(\n",
                "            *[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
                "        self.final_layer_norm = nn.LayerNorm(n_embd)\n",
                "        self.final_linear_layer = nn.Linear(n_embd, vocab_size)\n",
                "\n",
                "        self.apply(self._init_weights)\n",
                "\n",
                "    def _init_weights(self, module: nn.Module) -> None:\n",
                "        if isinstance(module, nn.Linear):\n",
                "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
                "            if module.bias is not None:\n",
                "                torch.nn.init.zeros_(module.bias)\n",
                "        elif isinstance(module, nn.Embedding):\n",
                "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
                "\n",
                "    def forward(self, input_tokens: torch.Tensor, targets: Optional[torch.Tensor] = None) -> Tuple[torch.Tensor, Optional[torch.Tensor]]:\n",
                "        \"\"\"\n",
                "        Forward pass of the model.\n",
                "\n",
                "        Args:\n",
                "            input_tokens: Tensor of token indices of shape (batch_size, sequence_length)\n",
                "            targets: Optional tensor of target token indices of same shape as input_tokens\n",
                "\n",
                "        Returns:\n",
                "            Tuple of (logits, loss) where logits has shape (batch_size, sequence_length, vocab_size)\n",
                "            and loss is optional cross-entropy loss if targets are provided\n",
                "        \"\"\"\n",
                "\n",
                "        B, T = input_tokens.shape\n",
                "\n",
                "        # input_tokens and targets are both (B,T) tensor of integers\n",
                "        token_embedding = self.token_embedding_table(input_tokens)  # (B,T,C)\n",
                "        positional_embedding = self.position_embedding_table(\n",
                "            torch.arange(T, device=device))  # (T,C)\n",
                "        x = token_embedding + positional_embedding  # (B,T,C)\n",
                "        x = self.blocks(x)  # (B,T,C)\n",
                "        x = self.final_layer_norm(x)  # (B,T,C)\n",
                "        logits = self.final_linear_layer(x)  # (B,T,vocab_size)\n",
                "\n",
                "        if targets is None:\n",
                "            loss = None\n",
                "        else:\n",
                "            B, T, C = logits.shape\n",
                "            logits = logits.view(B*T, C)\n",
                "            targets = targets.view(B*T)\n",
                "            loss = F.cross_entropy(logits, targets)\n",
                "\n",
                "        return logits, loss\n",
                "\n",
                "    def generate(self, input_tokens: torch.Tensor, max_new_tokens: int) -> torch.Tensor:\n",
                "        \"\"\"\n",
                "                Generate new tokens given a context.\n",
                "\n",
                "                Args:>ns: Starting token indices of shape (batch_size, sequence_length)\n",
                "                        max_new_tokens: Number of new tokens to generate\n",
                "\n",
                "                Returns:\n",
                "                        Tensor of token indices of shape (batch_size, sequence_length + max_new_tokens)\n",
                "                \"\"\"\n",
                "\n",
                "        # input_tokens is (B, T) array of indices in the current context\n",
                "        for _ in range(max_new_tokens):\n",
                "            # crop input_tokens to the last block_size tokens\n",
                "            cropped_input = input_tokens[:, -block_size:]\n",
                "            # get the predictions\n",
                "            logits, _ = self(cropped_input)\n",
                "            # focus only on the last time step\n",
                "            logits = logits[:, -1, :]  # becomes (B, C)\n",
                "            # apply softmax to get probabilities\n",
                "            probs = F.softmax(logits, dim=-1)  # (B, C)\n",
                "            # sample from the distribution\n",
                "            idx_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
                "            # append sampled index to the running sequence\n",
                "            input_tokens = torch.cat(\n",
                "                (input_tokens, idx_next), dim=1)  # (B, T+1)\n",
                "        return input_tokens"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {
                "cell_id": "a20642231579486eb85909edc065f177",
                "deepnote_cell_type": "code",
                "execution_context_id": "5c07c2dd-95b5-4d75-8e71-757b6df90be6",
                "execution_millis": 3158,
                "execution_start": 1745505467215,
                "source_hash": "f310bba6"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "22.467336 M parameters\n"
                    ]
                }
            ],
            "source": [
                "model = GPTLanguageModel()\n",
                "model = model.to(device)\n",
                "# print the number of parameters in the model\n",
                "print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cell_id": "202dad3095ed497db15b09ce4bf8d69a",
                "deepnote_cell_type": "text-cell-p"
            },
            "source": [
                "I'll help you create a training loop for the PoyoLLM model. First, let's create a training function that includes learning rate scheduling, gradient clipping, and proper device handling."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {
                "cell_id": "8aae586bd45e4117a876fd1816eaad64",
                "deepnote_cell_type": "code",
                "deepnote_variable_name": "",
                "execution_context_id": "5c07c2dd-95b5-4d75-8e71-757b6df90be6",
                "execution_millis": 0,
                "execution_start": 1745505470435,
                "source_hash": "bcbc406",
                "sql_integration_id": ""
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Training function created successfully!\n"
                    ]
                }
            ],
            "source": [
                "import torch\n",
                "from torch.optim import AdamW\n",
                "from torch.nn import functional as F\n",
                "import numpy as np\n",
                "from tqdm import tqdm\n",
                "\n",
                "def train_model(\n",
                "    model,\n",
                "    train_data,\n",
                "    val_data=None,\n",
                "    n_epochs=5,\n",
                "    batch_size=32,\n",
                "    learning_rate=3e-4,\n",
                "    max_grad_norm=1.0,\n",
                "    warmup_steps=2000,\n",
                "    eval_interval=500,\n",
                "    save_interval=1000,\n",
                "    checkpoint_dir='checkpoints'\n",
                "):\n",
                "    # Create optimizer\n",
                "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
                "    \n",
                "    # Learning rate scheduler\n",
                "    def get_lr(step, warmup_steps, learning_rate):\n",
                "        # Linear warmup followed by cosine decay\n",
                "        if step < warmup_steps:\n",
                "            return learning_rate * step / warmup_steps\n",
                "        return learning_rate * 0.5 * (1 + np.cos(np.pi * (step - warmup_steps) / (n_epochs * len(train_data) - warmup_steps)))\n",
                "    \n",
                "    # Training loop\n",
                "    step = 0\n",
                "    best_val_loss = float('inf')\n",
                "    \n",
                "    for epoch in range(n_epochs):\n",
                "        model.train()\n",
                "        pbar = tqdm(range(0, len(train_data), batch_size), desc=f'Epoch {epoch+1}/{n_epochs}')\n",
                "        \n",
                "        for i in pbar:\n",
                "            # Get batch\n",
                "            batch_data = train_data[i:i+batch_size]\n",
                "            if isinstance(batch_data, torch.Tensor):\n",
                "                x = batch_data\n",
                "                y = batch_data\n",
                "            else:\n",
                "                x = torch.tensor(batch_data, dtype=torch.long, device=device)\n",
                "                y = torch.tensor(batch_data, dtype=torch.long, device=device)\n",
                "            \n",
                "            # Forward pass\n",
                "            logits, loss = model(x, y)\n",
                "            \n",
                "            # Backward pass\n",
                "            optimizer.zero_grad(set_to_none=True)\n",
                "            loss.backward()\n",
                "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
                "            \n",
                "            # Update learning rate\n",
                "            lr = get_lr(step, warmup_steps, learning_rate)\n",
                "            for param_group in optimizer.param_groups:\n",
                "                param_group['lr'] = lr\n",
                "            \n",
                "            # Update weights\n",
                "            optimizer.step()\n",
                "            \n",
                "            # Update progress bar\n",
                "            pbar.set_postfix({'loss': f'{loss.item():.4f}', 'lr': f'{lr:.2e}'})\n",
                "            \n",
                "            # Evaluate on validation set\n",
                "            if val_data is not None and step % eval_interval == 0:\n",
                "                model.eval()\n",
                "                val_losses = []\n",
                "                with torch.no_grad():\n",
                "                    for j in range(0, len(val_data), batch_size):\n",
                "                        val_batch = val_data[j:j+batch_size]\n",
                "                        if isinstance(val_batch, torch.Tensor):\n",
                "                            val_x = val_batch\n",
                "                            val_y = val_batch\n",
                "                        else:\n",
                "                            val_x = torch.tensor(val_batch, dtype=torch.long, device=device)\n",
                "                            val_y = torch.tensor(val_batch, dtype=torch.long, device=device)\n",
                "                        _, val_loss = model(val_x, val_y)\n",
                "                        val_losses.append(val_loss.item())\n",
                "                \n",
                "                avg_val_loss = np.mean(val_losses)\n",
                "                print(f'\\nStep {step}: Validation loss: {avg_val_loss:.4f}')\n",
                "                \n",
                "                # Save best model\n",
                "                if avg_val_loss < best_val_loss:\n",
                "                    best_val_loss = avg_val_loss\n",
                "                    torch.save({\n",
                "                        'epoch': epoch,\n",
                "                        'model_state_dict': model.state_dict(),\n",
                "                        'optimizer_state_dict': optimizer.state_dict(),\n",
                "                        'loss': best_val_loss,\n",
                "                    }, f'{checkpoint_dir}/best_model.pt')\n",
                "                \n",
                "                model.train()\n",
                "            \n",
                "            # Save periodic checkpoint\n",
                "            if step % save_interval == 0:\n",
                "                torch.save({\n",
                "                    'epoch': epoch,\n",
                "                    'model_state_dict': model.state_dict(),\n",
                "                    'optimizer_state_dict': optimizer.state_dict(),\n",
                "                    'loss': loss.item(),\n",
                "                }, f'{checkpoint_dir}/checkpoint_{step}.pt')\n",
                "            \n",
                "            step += 1\n",
                "            \n",
                "    return model\n",
                "\n",
                "print(\"Training function created successfully!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cell_id": "6222c4720018434e80237cf3f060910e",
                "deepnote_cell_type": "text-cell-p"
            },
            "source": [
                "I'll create a helper function that loads the vocabulary and prepares the training data. Let me build this in steps."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {
                "cell_id": "a3d25c8de01949d6b4f970b38781826d",
                "deepnote_cell_type": "code",
                "deepnote_variable_name": "",
                "execution_context_id": "5c07c2dd-95b5-4d75-8e71-757b6df90be6",
                "execution_millis": 2,
                "execution_start": 1745505470494,
                "source_hash": "b9a3a993",
                "sql_integration_id": ""
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Total sequences: 1\n",
                        "Training sequences: 0\n",
                        "Validation sequences: 1\n"
                    ]
                }
            ],
            "source": [
                "def load_and_split_data(tokenizer, split_ratio=0.9, sequence_length=block_size):\n",
                "    # Load and process text\n",
                "    vocab_list = []\n",
                "    for word, value in tokenizer.vocab.items():\n",
                "        if isinstance(word, str):  # Only process string tokens\n",
                "            vocab_list.append(word)\n",
                "    \n",
                "    # Create a long text by joining words with spaces\n",
                "    text = ' '.join(vocab_list)\n",
                "    \n",
                "    # Convert text to token indices using tokenizer\n",
                "    tokens = tokenizer.encode(text)  # Changed tokenize to encode\n",
                "    \n",
                "    # Convert to tensor\n",
                "    data = torch.tensor(tokens, dtype=torch.long, device=device)\n",
                "    \n",
                "    # Create sequences of fixed length\n",
                "    n_sequences = max(1, len(data) - sequence_length)  # Ensure at least one sequence\n",
                "    sequences = []\n",
                "    for i in range(n_sequences):\n",
                "        seq = data[i:i+sequence_length]\n",
                "        # Pad sequence if necessary\n",
                "        if len(seq) < sequence_length:\n",
                "            padding = torch.zeros(sequence_length - len(seq), dtype=torch.long, device=device)\n",
                "            seq = torch.cat([seq, padding])\n",
                "        sequences.append(seq)\n",
                "    \n",
                "    sequences = torch.stack(sequences)\n",
                "    \n",
                "    # Split into train and validation\n",
                "    split_idx = int(len(sequences) * split_ratio)\n",
                "    train_data = sequences[:split_idx]\n",
                "    val_data = sequences[split_idx:]\n",
                "    \n",
                "    print(f\"Total sequences: {len(sequences)}\")\n",
                "    print(f\"Training sequences: {len(train_data)}\")\n",
                "    print(f\"Validation sequences: {len(val_data)}\")\n",
                "    \n",
                "    return train_data, val_data\n",
                "\n",
                "# Test the function\n",
                "train_data, val_data = load_and_split_data(tokenizer)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {
                "cell_id": "9c01e9a14d8e4f9dbcb5ef1bad71f50b",
                "deepnote_cell_type": "code",
                "deepnote_variable_name": "",
                "execution_context_id": "5c07c2dd-95b5-4d75-8e71-757b6df90be6",
                "execution_millis": 5,
                "execution_start": 1745505470553,
                "source_hash": "5304a81f",
                "sql_integration_id": ""
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Total sequences: 3005\n",
                        "Training sequences: 2704\n",
                        "Validation sequences: 301\n"
                    ]
                }
            ],
            "source": [
                "def load_and_split_data(tokenizer, split_ratio=0.9, sequence_length=block_size):\n",
                "    # Get all text from vocab (converting integers to strings if necessary)\n",
                "    vocab_list = []\n",
                "    for word in tokenizer.vocab.keys():\n",
                "        if isinstance(word, int):\n",
                "            vocab_list.append(str(word))\n",
                "        else:\n",
                "            vocab_list.append(word)\n",
                "    \n",
                "    # Join all words with spaces\n",
                "    text = \" \".join(vocab_list)\n",
                "    \n",
                "    # Convert text to token indices\n",
                "    tokens = tokenizer.encode(text)\n",
                "    \n",
                "    # Convert to tensor\n",
                "    data = torch.tensor(tokens, dtype=torch.long, device=device)\n",
                "    \n",
                "    # Create sequences of fixed length\n",
                "    n_sequences = len(data) - sequence_length\n",
                "    if n_sequences <= 0:\n",
                "        raise ValueError(f\"Data length ({len(data)}) is shorter than sequence length ({sequence_length})\")\n",
                "    \n",
                "    sequences = torch.stack([data[i:i+sequence_length] for i in range(n_sequences)])\n",
                "    \n",
                "    # Split into train and validation\n",
                "    split_idx = int(len(sequences) * split_ratio)\n",
                "    train_data = sequences[:split_idx]\n",
                "    val_data = sequences[split_idx:]\n",
                "    \n",
                "    print(f\"Total sequences: {len(sequences)}\")\n",
                "    print(f\"Training sequences: {len(train_data)}\")\n",
                "    print(f\"Validation sequences: {len(val_data)}\")\n",
                "    \n",
                "    return train_data, val_data\n",
                "\n",
                "# Test the function\n",
                "train_data, val_data = load_and_split_data(tokenizer)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "cell_id": "c0ba65e3490d41719155b2b1df98f714",
                "deepnote_cell_type": "code",
                "deepnote_variable_name": "",
                "execution_context_id": "5c07c2dd-95b5-4d75-8e71-757b6df90be6",
                "execution_millis": 11204,
                "execution_start": 1745505470624,
                "source_hash": "c94e7070",
                "sql_integration_id": ""
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/3:   0%|          | 0/85 [00:00<?, ?it/s]"
                    ]
                }
            ],
            "source": [
                "# Now we can try training the model with our data\n",
                "from pathlib import Path\n",
                "\n",
                "# Create checkpoints directory if it doesn't exist\n",
                "Path(\"checkpoints\").mkdir(exist_ok=True)\n",
                "\n",
                "# Start training\n",
                "train_model(\n",
                "    model=model,\n",
                "    train_data=train_data,\n",
                "    val_data=val_data,\n",
                "    n_epochs=3,\n",
                "    batch_size=32,\n",
                "    learning_rate=3e-4,\n",
                "    warmup_steps=100,\n",
                "    eval_interval=100,\n",
                "    save_interval=500,\n",
                "    checkpoint_dir='checkpoints'\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "created_in_deepnote_cell": true,
                "deepnote_cell_type": "markdown"
            },
            "source": [
                "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=5a923484-3c6f-40ab-ba4a-906a4dff832d' target=\"_blank\">\n",
                "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
                "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
            ]
        }
    ],
    "metadata": {
        "deepnote_notebook_id": "41ae46fb6ee54803957520ce9bf15416",
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.13.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
